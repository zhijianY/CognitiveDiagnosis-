{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from initial_dataSet4 import DataSet\n",
    "from model_4 import CICDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_param(save_dir, name, param):\n",
    "    np.savetxt(save_dir + name, param.cpu().detach().numpy(), fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.zeros(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def split_record(record, test_ratio=0.2):\n",
    "    # print(\"record.index:\",record.index)\n",
    "    total_stu_list = set(record.index)\n",
    "    train_data = [[], [], [],[]]\n",
    "    test_data = [[], [], [],[]]\n",
    "    for stu in tqdm(total_stu_list, \"[split record:]\"):\n",
    "        stu_data = record.loc[stu, :]\n",
    "        stu_item = np.array(stu_data['item_id'])\n",
    "        stu_score = np.array(stu_data['score'])\n",
    "        stu_school = np.array(stu_data['school_id'])\n",
    "\n",
    "        # print(\"paramter\",stu_item,stu_score,stu_school)\n",
    "\n",
    "        length = len(stu_item)\n",
    "        index_list = list(range(length))\n",
    "        test_index = random.sample(index_list, int(length * test_ratio))\n",
    "        train_index = list(set(index_list) - set(test_index))\n",
    "\n",
    "        train_data[0].extend([stu] * len(train_index))\n",
    "        train_data[1].extend(stu_item[train_index])\n",
    "        train_data[2].extend(stu_score[train_index])\n",
    "        train_data[3].extend(stu_school[train_index])\n",
    "\n",
    "        test_data[0].extend([stu] * len(test_index))\n",
    "        test_data[1].extend(stu_item[test_index])\n",
    "        test_data[2].extend(stu_score[test_index])\n",
    "        test_data[3].extend(stu_school[test_index])\n",
    "\n",
    "    train = pd.DataFrame({'user_id': train_data[0], 'item_id': train_data[1], 'score': train_data[2],'school_id': train_data[3]}).set_index('user_id')\n",
    "    test = pd.DataFrame({'user_id': test_data[0], 'item_id': test_data[1], 'score': test_data[2],'school_id': test_data[3]}).set_index('user_id')\n",
    "    return train, test\n",
    "\n",
    "\n",
    "class DataSet():\n",
    "    def __init__(self, basedir, dataSetName, build=False):\n",
    "        self.basedir = basedir\n",
    "        self.dataSetName = dataSetName\n",
    "        if dataSetName == 'FrcSub':\n",
    "            read_dir = basedir + 'data/frcSub/'\n",
    "            save_result_dir = basedir + 'output/result/frcSub/'\n",
    "            save_parameter_dir = basedir + 'output/parameter/frcSub/'\n",
    "            N = 536\n",
    "            J = 20\n",
    "            K = 8\n",
    "        elif dataSetName == 'Math1':\n",
    "            read_dir = basedir + 'data/math1/'\n",
    "            save_result_dir = basedir + 'output/result/math1/'\n",
    "            save_parameter_dir = basedir + 'output/parameter/math1/'\n",
    "            N = 4209\n",
    "            J = 20\n",
    "            K = 11\n",
    "        elif dataSetName == 'Math2':\n",
    "            read_dir = basedir + 'data/math2/'\n",
    "            save_result_dir = basedir + 'output/result/math2/'\n",
    "            save_parameter_dir = basedir + 'output/parameter/math2/'\n",
    "            N = 3911\n",
    "            J = 20\n",
    "            K = 16\n",
    "        elif dataSetName == 'ASSIST_0910':\n",
    "            read_dir = basedir + 'data/a0910/'\n",
    "            save_result_dir = basedir + 'output/result/a0910/'\n",
    "            save_parameter_dir = basedir + 'output/parameter/a0910/'\n",
    "            # N = 2392\n",
    "            # J = 17657\n",
    "            # K = 123\n",
    "            # N = 2380\n",
    "            # M = 48\n",
    "            # J = 16804\n",
    "            # K = 110\n",
    "            N = 2380  #学生数量\n",
    "            M = 48     #学校数量\n",
    "            J = 16804   #记录数\n",
    "            K = 110     #知识点\n",
    "        elif dataSetName == 'ASSIST_2017':\n",
    "            read_dir = basedir + 'data/a2017/'\n",
    "            # save_result_dir = basedir + 'output/result/a2017/'\n",
    "            save_result_dir =  'output/result/a2017/'\n",
    "            save_parameter_dir = basedir + 'output/parameter/a2017/'\n",
    "            N = 1678\n",
    "            J = 2210\n",
    "            K = 101\n",
    "        elif dataSetName == 'MAT_2016':\n",
    "            read_dir = basedir + 'data/mat2016/'\n",
    "            save_result_dir = basedir + 'output/result/mat2016/'\n",
    "            save_parameter_dir = basedir + 'output/parameter/mat2016/'\n",
    "            N = 6866\n",
    "            J = 1847\n",
    "            K = 445\n",
    "        elif dataSetName == 'JUNYI':\n",
    "            read_dir = basedir + 'data/junyi/'\n",
    "            save_result_dir = basedir + 'output/result/junyi/'\n",
    "            save_parameter_dir = basedir + 'output/parameter/junyi/'\n",
    "            N = 36591\n",
    "            J = 721\n",
    "            K = 721\n",
    "        else:\n",
    "            print('Dataset does not exist!')\n",
    "            exit(0)\n",
    "        print('DataSet:', dataSetName)\n",
    "        item = pd.read_csv(read_dir + \"item.csv\").set_index('item_id')\n",
    "        data = pd.read_csv(read_dir + \"record2.csv\").set_index('user_id')\n",
    "\n",
    "        if not build:\n",
    "            conc_relation = pd.read_csv(read_dir + \"concept_relationship.csv\")\n",
    "            self.conc_relation = conc_relation\n",
    "\n",
    "        self.total_stu_list = np.unique(data.index)\n",
    "        self.student_num = N\n",
    "        self.school_num = M\n",
    "        self.exercise_num = J\n",
    "        self.concept_num = K\n",
    "        self.record = data\n",
    "        self.item = item\n",
    "\n",
    "        self.read_dir = read_dir\n",
    "        self.save_result_dir = save_result_dir\n",
    "        self.save_parameter_dir = save_parameter_dir\n",
    "\n",
    "    def get_train_test(self, record, test_ratio=0.2):\n",
    "        print('test_ratio:', test_ratio)\n",
    "        train, test = split_record(record, test_ratio=test_ratio)\n",
    "        return train, test\n",
    "\n",
    "    def get_item_concept_df(self) -> pd.DataFrame:\n",
    "        item = self.item\n",
    "        item = item[~item.index.duplicated()]  # 去除重复项\n",
    "        item_list, concept_list = [], []\n",
    "        for idx in item.index:\n",
    "            now_concept_list = eval(item.loc[idx, 'knowledge_code'])\n",
    "            item_list.extend([idx] * len(now_concept_list))\n",
    "            concept_list.extend(now_concept_list)\n",
    "        item_conc_idx = range(len(concept_list))\n",
    "        return pd.DataFrame({'item': item_list, 'concept': concept_list, 'item_conc_index': item_conc_idx}).astype('int')\n",
    "\n",
    "    def get_exer_conc_adj(self):\n",
    "        Q = np.zeros((self.exercise_num, self.concept_num), dtype='bool')\n",
    "        item = self.item\n",
    "        item = item[~item.index.duplicated()]\n",
    "        for idx in item.index:\n",
    "            know_list = eval(item.loc[idx, 'knowledge_code'])  # eval 函数可将数值字符串转换为数值\n",
    "            Q[np.array([idx] * len(know_list)) - 1, np.array(know_list) - 1] = True\n",
    "        return torch.tensor(Q, dtype=torch.float)\n",
    "\n",
    "    def get_conc_conc_adj(self):\n",
    "        conc_graph = np.zeros((self.concept_num, self.concept_num), dtype='bool')\n",
    "        conc_graph[self.conc_relation['parent'] - 1, self.conc_relation['knowledge_code'] - 1] = True\n",
    "        return torch.tensor(conc_graph, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习者作答习题时的得分不仅仅受到知识点的影响，还受到学习者的其他技能的影响\n",
    "# 组织形式：Y=(1-λ)*Y_A + λ*Y_B    \n",
    "#加入学校特征后: Y = （1-λ）*Y_A +λ*Y_B+λ*Y_M\n",
    "\n",
    "# A：学习者对知识点的熟练程度，大小=N*K\n",
    "# B：学习者除知识点外的其他技能，大小=N*8\n",
    "# C：学习者在知识簇上的属性，大小=N*K\n",
    "# H：知识点的交互，大小=K*K\n",
    "# W：习题与知识点的权重矩阵，大小=J*K，其中元素sigmoid函数后再除以行/列累加和归一化\n",
    "# D：习题与其他技能的权重，大小=J*8，其中元素用行/列softmax函数归一化\n",
    "# lambda：其他技能对答题记录的影响权重\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn, Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from initial_dataSet import DataSet\n",
    "\n",
    "\n",
    "def format_data(record, n_splits=5):\n",
    "    train = [[], [], []]  # 学生,习题，得分\n",
    "    label = [[], [], []]  # 学生,习题，得分\n",
    "    stu_list = set(record.index)\n",
    "\n",
    "    KF = KFold(n_splits=n_splits, shuffle=True)  # 5折交叉验证\n",
    "    count = 0\n",
    "    for stu in stu_list:\n",
    "        stu_item = record.loc[[stu], 'item_id'].values - 1\n",
    "        stu_scohol = record.loc[[stu], 'school_id'].values - 1\n",
    "        stu_score = record.loc[[stu], 'score'].values\n",
    "        if len(stu_item) >= n_splits:\n",
    "\n",
    "            for train_prob, label_prob in KF.split(stu_item):\n",
    "                train[0].append(stu - 1)\n",
    "                train[1].append(stu_item[train_prob])\n",
    "                train[2].append(stu_score[train_prob])\n",
    "\n",
    "\n",
    "                label[0].extend([count] * len(label_prob))\n",
    "                label[1].extend(stu_item[label_prob])\n",
    "                label[2].extend(stu_score[label_prob])\n",
    "\n",
    "                count += 1\n",
    "    return train, label\n",
    "\n",
    "\n",
    "def format_test_data(record, test_record):\n",
    "    train = [[], [], []]  # 学生,习题，得分\n",
    "    test = [[], [], []]  # 学生,习题，得分\n",
    "    stu_list = set(record.index)\n",
    "\n",
    "    count = 0\n",
    "    for stu in stu_list:\n",
    "        stu_item = record.loc[[stu], 'item_id'].values - 1\n",
    "        stu_score = record.loc[[stu], 'score'].values\n",
    "        stu_school = record.loc[[stu], 'school_id'].values -1\n",
    "\n",
    "        test_item = test_record.loc[[stu], 'item_id'].values - 1\n",
    "        test_score = test_record.loc[[stu], 'score'].values\n",
    "        test_school = test_school.loc[[stu], 'school_id'].values -1\n",
    "\n",
    "        train[0].append(stu - 1)\n",
    "        train[1].append(stu_item)\n",
    "        train[2].append(stu_score)\n",
    "        # train[3].append(stu_school)\n",
    "\n",
    "        test[0].extend([count] * len(test_item))\n",
    "        test[1].extend(test_item)\n",
    "        test[2].extend(test_score)\n",
    "        # test[3].extend(test_school)\n",
    "        count += 1\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def format_all_data(all_record):\n",
    "    data = [[], [], [],[]]  # 学生,习题，得分，学校\n",
    "    stu_list = set(all_record.index)\n",
    "\n",
    "    for stu in stu_list:\n",
    "        stu_item = all_record.loc[[stu], 'item_id'].values - 1\n",
    "        stu_score = all_record.loc[[stu], 'score'].values\n",
    "        stu_school = all_record.loc[[stu], 'school_id'].values -1\n",
    "\n",
    "        data[0].append(stu - 1)\n",
    "        data[1].append(stu_item)\n",
    "        data[2].append(stu_score)\n",
    "        data[3].append(stu_school)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def evaluate(pred, label):\n",
    "    acc = metrics.accuracy_score(np.array(label).round(), np.array(pred).round())\n",
    "    try:\n",
    "        auc = metrics.roc_auc_score(np.array(label).round(), np.array(pred))\n",
    "    except ValueError:\n",
    "        auc = 0.5\n",
    "    mae = metrics.mean_absolute_error(label, pred)\n",
    "    rmse = metrics.mean_squared_error(label, pred)**0.5\n",
    "    return acc, auc, rmse, mae\n",
    "\n",
    "\n",
    "class CICDM_Net(nn.Module):\n",
    "    def __init__(self, concept_num: int, school_feature_dim: int,exercise_num: int, exer_conc_adj: Tensor,\n",
    "                 conc_conc_adj: Tensor, potential_num: int = 32, conc_conc_ini_w: int = 5,\n",
    "                 only_A: bool = False, device: str = 'cpu') -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        #增加学校特征权重矩阵\n",
    "\n",
    "        self.school_feature_dim = school_feature_dim\n",
    "        self.school_feature_dim_w = nn.Parameter(torch.randn(school_feature_dim,potential_num))\n",
    "\n",
    "\n",
    "\n",
    "        assert exer_conc_adj.size(0) == exercise_num and exer_conc_adj.size(1) == concept_num, 'exercise_concept adjacency matrix size wrong!'\n",
    "        assert conc_conc_adj.size(0) == conc_conc_adj.size(1) == concept_num, 'concept_concept adjacency matrix size wrong!'\n",
    "        self.device = device\n",
    "        self.only_A = only_A\n",
    "\n",
    "        self.concept_num = concept_num\n",
    "        self.exercise_num = exercise_num\n",
    "        self.potential_num = potential_num\n",
    "        self.exer_conc_adj = exer_conc_adj\n",
    "        self.exer_conc_w = nn.Parameter(torch.randn_like(exer_conc_adj))\n",
    "\n",
    "        conc_conc_adj[torch.eye(concept_num, dtype=torch.bool)] = 1\n",
    "        self.conc_conc_w = nn.Parameter(conc_conc_adj * conc_conc_ini_w)\n",
    "\n",
    "        if not only_A:\n",
    "\n",
    "            self.exer_pote_w = nn.Parameter(torch.randn((exercise_num, potential_num)))\n",
    "            self.lambd = nn.Parameter(torch.ones((1, exercise_num)) * -2)\n",
    "\n",
    "        self.guess = nn.Parameter(torch.ones((1, exercise_num)) * -2)\n",
    "        self.slide = nn.Parameter(torch.ones((1, exercise_num)) * -2)\n",
    "\n",
    "    def forward(self, exer_list, score_list,school_feature) -> Tuple[Tensor, Tensor]:\n",
    "        A = torch.empty(len(score_list), self.concept_num).to(self.device)\n",
    "        W = torch.sigmoid(self.exer_conc_w) * self.exer_conc_adj\n",
    "        W2 = W / W.sum(dim=1).reshape(-1, 1)\n",
    "\n",
    "        # print(school_feature.ndim,len(school_feature),school_feature.shape,school_feature)\n",
    "        # print(\"a' dimension：\",A.shape,A)     #A:192*110\n",
    "        # print(\"school_feature:\",school_feature.ndim,\",\",len(school_feature),\",\",school_feature.shape)  #192*1\n",
    "        # # print(\"school_feature_w' dimension：\",school_feature_w.shape,school_feature_w)\n",
    "\n",
    "        # #加入学校特征\n",
    "        # if school_feature.ndim == 1:\n",
    "        #     # 如果 school_feature 是一维的，假设它表示单个学校的特征\n",
    "        #     school_feature = school_feature.unsqueeze(0)  # 转换为 (1, 48)\n",
    "        # elif school_feature.size(1) != 48:\n",
    "        #     # 如果 school_feature 不是 (batch_size, 48)，需要调整它\n",
    "        #     # 这里的逻辑取决于 school_feature 的实际数据结构和意图\n",
    "        #     # 例如，如果每个学校有一个特征值，可以尝试以下转换：\n",
    "        #     school_feature = school_feature.expand(-1, 48)  # 扩展为 (batch_size, 48)\n",
    "        # print(\"school_feature:\",school_feature)\n",
    "\n",
    "        # school_feature_transformed = torch.matmul(school_feature,self.school_feature_dim_w)\n",
    "        # school_feature_transformed = school_feature_transformed.view(1, -1)  # Reshape to [1, 13]\n",
    "        # # Ensure it's the correct size\n",
    "        # school_feature_transformed = school_feature_transformed[:, :] \n",
    "\n",
    "        slide = torch.sigmoid(self.slide)\n",
    "        guess = torch.sigmoid(self.guess)\n",
    "\n",
    "        if not self.only_A:\n",
    "            B = torch.empty(len(score_list), self.potential_num).to(self.device)\n",
    "            D2 = torch.softmax(self.exer_pote_w, dim=1)\n",
    "            lambd = torch.sigmoid(self.lambd)\n",
    "\n",
    "        for i, X_i in enumerate(score_list):\n",
    "            X_i = torch.tensor(X_i).float().to(self.device).reshape(1, -1)\n",
    "            \n",
    "            # print(\"X_i\",X_i.shape,\"   school_feature_transformed\",school_feature_transformed[i].shape)\n",
    "            # transformed_feature = school_feature_transformed[i]\n",
    "            # if transformed_feature.size(0) != X_i.size(1):\n",
    "            #     if transformed_feature.size(0) < X_i.size(1):\n",
    "            #         # Pad if transformed_feature is smaller\n",
    "            #         padding_size = X_i.size(1) - transformed_feature.size(0)\n",
    "            #         transformed_feature = nn.pad(transformed_feature, (0, padding_size), \"constant\", 0)\n",
    "            #     else:\n",
    "            #         # Truncate if transformed_feature is larger\n",
    "            #         transformed_feature = transformed_feature[:X_i.size(1)]\n",
    "            \n",
    "            # print(\"X_i.shape:\",X_i.shape)\n",
    "            # print(\"school_feature_transformed[i]\",i,\":\",school_feature_transformed[i])\n",
    "\n",
    "            # X_i = X_i + school_feature_transformed[i]\n",
    "\n",
    "            # --------Knowledge concept start---------------\n",
    "            W1_i_ = W[exer_list[i]]\n",
    "            W1_i_sum = W1_i_.sum(dim=0)  # The cumulative sum of concepts not involved is 0\n",
    "            W1_i = W1_i_[:, W1_i_sum != 0] / W1_i_sum[W1_i_sum != 0].reshape(1, -1)\n",
    "            A1_i = X_i @ W1_i\n",
    "            H1_i = torch.softmax(self.conc_conc_w[W1_i_sum != 0], dim=0)\n",
    "            A[i] = A1_i @ H1_i\n",
    "            # --------Knowledge concept end---------------\n",
    "\n",
    "            if not self.only_A:\n",
    "                # --------Skill start---------------\n",
    "                D1_i_ = self.exer_pote_w[exer_list[i]]\n",
    "                D1_i = torch.softmax(D1_i_, dim=0)\n",
    "                B[i] = X_i @ D1_i\n",
    "                # --------Skill end-----------------\n",
    "\n",
    "        Y_A = A @ W2.T\n",
    "        if not self.only_A:\n",
    "            Y_B = B @ D2.T\n",
    "            Y_ = (1 - lambd) * Y_A + lambd * Y_B\n",
    "        else:\n",
    "            Y_ = Y_A\n",
    "        Y_ = Y_.clamp(1e-8, 1 - 1e-8)\n",
    "        Y = (1 - slide) * Y_ + guess * (1 - Y_)\n",
    "\n",
    "        return A, Y\n",
    "\n",
    "\n",
    "class CICDM():\n",
    "    # def __init__(self, student_num: int, school_num: int,concept_num: int, exercise_num: int, exer_conc_adj: Tensor,\n",
    "    def __init__(self, student_num: int,concept_num: int, exercise_num: int, exer_conc_adj: Tensor,\n",
    "                 conc_conc_adj: Tensor, potential_num: int = 32, lr: float = 0.001,\n",
    "                 only_A: bool = False, device: str = 'cpu') -> None:\n",
    "        # self.cd_net = CICDM_Net(concept_num,school_num, exercise_num, exer_conc_adj.to(device),\n",
    "        self.cd_net = CICDM_Net(concept_num, exercise_num, exer_conc_adj.to(device),\n",
    "                                conc_conc_adj.to(device), potential_num, only_A=only_A, device=device).to(device)\n",
    "        self.device = device\n",
    "        self.student_num = student_num\n",
    "        self.concept_num = concept_num\n",
    "        # self.school_num = school_num\n",
    "        self.exercise_num = exercise_num\n",
    "        self.optimizer = torch.optim.Adam(self.cd_net.parameters(), lr=lr)\n",
    "        self.loss = torch.nn.BCELoss(reduction='mean')\n",
    "\n",
    "    def fit(self, index_loader: DataLoader, train_df: pd.DataFrame, epochs: int = 5,\n",
    "            n_splits: int = 5, test_df: pd.DataFrame = None) -> None:\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = []\n",
    "            for betch_data in tqdm(index_loader, \"[Epoch:%s]\" % (epoch + 1)):\n",
    "                stu_list = np.array([x.numpy() for x in betch_data], dtype='int').reshape(-1)\n",
    "                train_data, label_data = format_data(train_df.loc[stu_list, :], n_splits=n_splits)\n",
    "\n",
    "                # -----start training-------------------\n",
    "\n",
    "                ##修改\n",
    "                # max_length = max(len(f) for f in train_data[3])\n",
    "                # padded_school_features = [f + [0]*(max_length - len(f)) for f in train_data[3]]\n",
    "                # train_data[3] = torch.tensor(padded_school_features, dtype=torch.float).to(self.device)\n",
    "\n",
    "                # 确定最大长度\n",
    "                # max_length = max(len(f) for f in train_data[3])\n",
    "\n",
    "                # # 填充每个学校特征列表以匹配最大长度\n",
    "                # padded_school_features = []\n",
    "                # for f in train_data[3]:\n",
    "                #     # 确保 f 是列表\n",
    "                #     if not isinstance(f, list):\n",
    "                #         f = [f]\n",
    "                #     # 填充操作\n",
    "                #     padded_feature = f + [0] * (max_length - len(f))\n",
    "                #     padded_school_features.append(padded_feature)\n",
    "                # train_data[3] = torch.tensor(padded_school_features, dtype=torch.float).to(self.device)\n",
    "\n",
    "                # max_length = max(len(f) if isinstance(f, list) else 1 for f in train_data[3])\n",
    "\n",
    "                # # 填充每个特征列表以匹配最大长度\n",
    "                # padded_school_features = []\n",
    "                # for f in train_data[3]:\n",
    "                #     # 确保 f 是一个列表\n",
    "                #     if not isinstance(f, list):\n",
    "                #         f = [f]\n",
    "                #     # 确保列表中的所有元素都是浮点数\n",
    "                #     new_f = []\n",
    "                #     for element in f:\n",
    "                #         # 如果元素是单一数值，则直接转换\n",
    "                #         if isinstance(element, (int, float)):\n",
    "                #             new_f.append(float(element))\n",
    "                #         # 如果元素是数组或列表，处理数组或列表（例如，取第一个元素或计算平均值）\n",
    "                #         elif isinstance(element, (list, np.ndarray)) and len(element) > 0:\n",
    "                #             new_f.append(float(element[0]))  # 这里只是一个示例，具体取决于您的需求\n",
    "                #         else:\n",
    "                #             new_f.append(0.0)  # 如果无法处理，使用默认值\n",
    "                #     # 进行填充\n",
    "                #     padded_feature = new_f + [0.0] * (max_length - len(new_f))\n",
    "                #     padded_school_features.append(padded_feature)\n",
    "\n",
    "                # # 使用 NumPy 创建一个规整的二维数组\n",
    "                # padded_school_features_np = np.array(padded_school_features, dtype=float)\n",
    "\n",
    "                # # 转换为张量\n",
    "                # train_data[3] = torch.tensor(padded_school_features_np, dtype=torch.float).to(self.device)\n",
    "\n",
    "\n",
    "\n",
    "                _, all_pred = self.cd_net(train_data[1], train_data[2])\n",
    "                # _, all_pred = self.cd_net(train_data[1], train_data[2], train_data[3])\n",
    "                pred = all_pred[label_data[0], label_data[1]]\n",
    "                label = torch.FloatTensor(label_data[2]).to(self.device)\n",
    "                loss: Tensor = self.loss(pred, label)\n",
    "                # ------end training--------------------\n",
    "                epoch_loss.append(loss.item())\n",
    "\n",
    "                # ------start update parameters----------\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                # ------ end update parameters-----------\n",
    "            print('\\t{}th epoch loss = {}'.format(epoch + 1, np.mean(epoch_loss)))\n",
    "            if test_df is not None:\n",
    "                self.test(index_loader, train_df, test_df)\n",
    "\n",
    "    def test(self, index_loader: DataLoader, train_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple[float, float, float, float]:\n",
    "        test_pred_list, test_label_list = [], []\n",
    "        for betch_data in tqdm(index_loader, \"[Testing:]\"):\n",
    "            stu_list = np.array([x.numpy() for x in betch_data], dtype='int').reshape(-1)\n",
    "            train, test = format_test_data(train_df.loc[stu_list, :],\n",
    "                                           test_df.loc[stu_list, :])\n",
    "            with torch.no_grad():\n",
    "                _, all_pred = self.cd_net(train[1], train[2])\n",
    "                test_pred = all_pred[test[0], test[1]].clone().to('cpu').detach()\n",
    "                test_pred_list.extend(test_pred.tolist())\n",
    "                test_label_list.extend(test[2])\n",
    "        acc, auc, rmse, mae = evaluate(test_pred_list, test_label_list)\n",
    "        print(\"\\ttest_result: \\tacc:%.6f, auc:%.6f, rmse:%.6f, mae:%.6f\" % (acc, auc, rmse, mae))\n",
    "        return acc, auc, rmse, mae\n",
    "\n",
    "    def get_A_and_Y(self, index_loader: DataLoader, all_record: pd.DataFrame):\n",
    "        A = torch.empty((self.student_num, self.concept_num))\n",
    "        Y = torch.empty((self.student_num, self.exercise_num))\n",
    "        for betch_data in tqdm(index_loader, \"[get_A_and_Y:]\"):\n",
    "            stu_list = np.array([x.numpy() for x in betch_data], dtype='int').reshape(-1)\n",
    "            data = format_all_data(all_record.loc[stu_list, :])\n",
    "            with torch.no_grad():\n",
    "                cogn_state, all_pred = self.cd_net(data[1], data[2])\n",
    "                A[data[0], :] = cogn_state.cpu().detach()\n",
    "                Y[data[0], :] = all_pred.cpu().detach()\n",
    "        return A, Y\n",
    "\n",
    "\n",
    "# if __name__ =='__main__':\n",
    "#     a1 = torch.tensor([1])\n",
    "#     a2 = torch.tensor([1])\n",
    "#     print(\"a1:\",a1.shape,torch.concat(a1,a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet: ASSIST_0910\n",
      "test_ratio: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[split record:]: 100%|██████████| 2380/2380 [00:00<00:00, 4789.76it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataSet' object has no attribute 'school_num'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-489b695daf57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m model = CICDM(student_num=dataSet.student_num,\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mschool_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschool_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mconcept_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcept_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mexercise_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexercise_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataSet' object has no attribute 'school_num'"
     ]
    }
   ],
   "source": [
    "# ----------基本参数--------------\n",
    "basedir = './'\n",
    "# dataSet_list = ('ASSIST_0910', 'ASSIST_2017', 'JUNYI')\n",
    "dataSet_list = ('ASSIST_0910', 'ASSIST_2017', 'JUNYI', 'MathEC')\n",
    "epochs_list = (8, 13, 1, 2) \n",
    "\n",
    "dataSet_idx = 0\n",
    "test_ratio = 0.2\n",
    "batch_size = 64\n",
    "potential_num = 32\n",
    "learn_rate = 2e-2\n",
    "n_splits = 3\n",
    "\n",
    "data_set_name = dataSet_list[dataSet_idx]\n",
    "epochs = epochs_list[dataSet_idx]\n",
    "device = 'cuda'\n",
    "# ----------基本参数--------------\n",
    "\n",
    "dataSet = DataSet(basedir, data_set_name)\n",
    "# print(dataSet.record.head(3))\n",
    "# print(\"total_stu_list:\",dataSet.total_stu_list)\n",
    "# print(\"《《开始》》\")\n",
    "train_data, test_data = dataSet.get_train_test(dataSet.record, test_ratio=test_ratio)\n",
    "# print(\"《《结束》》\")\n",
    "exer_conc_adj = dataSet.get_exer_conc_adj()\n",
    "conc_conc_adj = dataSet.get_conc_conc_adj()\n",
    "\n",
    "total_stu_list = dataSet.total_stu_list\n",
    "# print(\"total_stu_list2222:\",dataSet.total_stu_list)\n",
    "\n",
    "model = CICDM(student_num=dataSet.student_num,\n",
    "        school_num = dataSet.school_num,\n",
    "        concept_num=dataSet.concept_num,\n",
    "        exercise_num=dataSet.exercise_num,\n",
    "        exer_conc_adj=exer_conc_adj,\n",
    "        conc_conc_adj=conc_conc_adj,\n",
    "        potential_num=potential_num,\n",
    "        lr=learn_rate,\n",
    "        device=device)\n",
    "# print(\"school_num:\",model.school_num)\n",
    "\n",
    "index_loader = DataLoader(TensorDataset(torch.tensor(list(total_stu_list)).float()),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model.fit(index_loader, train_data, epochs=epochs, n_splits=n_splits, test_df=test_data)\n",
    "# acc, auc, rmse, mae = model.test(index_loader, train_data, test_data)\n",
    "cognitive_state, score_pred = model.get_A_and_Y(index_loader, dataSet.record)\n",
    "\n",
    "# 存储参数\n",
    "save_param_dir = dataSet.save_parameter_dir\n",
    "save_param(save_param_dir, 'H.csv', torch.softmax(model.cd_net.conc_conc_w, dim=0))\n",
    "save_param(save_param_dir, 'lambda.csv', torch.sigmoid(model.cd_net.lambd))\n",
    "\n",
    "save_result_dir = dataSet.save_result_dir\n",
    "save_param(save_result_dir, 'cognitive_state1.csv', cognitive_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
